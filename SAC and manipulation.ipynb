{"cells":[{"cell_type":"markdown","source":"## Object Interceptions with Soft Actor-Critic Model","metadata":{"tags":[],"cell_id":"7d96da33658b4973b201f0fd7652c40d","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h2"}},{"cell_type":"markdown","source":"### Drake simulation setup code","metadata":{"tags":[],"cell_id":"b2b8c58d6fdc43969ca8fc37f95522a9","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"# Import libraries and functions for drake simulation\nimport numpy as np\nimport os\nimport random\n\nimport pydot\nfrom pydrake.all import (LeafSystem,Sphere, Box )\n\nfrom manipulation import running_as_notebook\nimport matplotlib.pyplot as plt\nfrom IPython.display import HTML, SVG, display\n\nfrom pydrake.common import FindResourceOrThrow, temp_directory\nfrom pydrake.geometry import (\n    MeshcatVisualizer,\n    MeshcatVisualizerParams,\n    Role,\n    StartMeshcat,\n)\nfrom pydrake.math import RollPitchYaw\n\n\nfrom pydrake.math import RigidTransform, RollPitchYaw\nfrom pydrake.multibody.meshcat import JointSliders\nfrom pydrake.multibody.parsing import Parser\nfrom pydrake.multibody.plant import AddMultibodyPlantSceneGraph\nfrom pydrake.systems.analysis import Simulator\nfrom pydrake.systems.framework import DiagramBuilder\n\nfrom manipulation.scenarios import MakeManipulationStation\n\n\nfrom pydrake.symbolic import Variable\nfrom pydrake.systems.primitives import SymbolicVectorSystem\nfrom pydrake.systems.framework import LeafSystem\n\nfrom manipulation.meshcat_utils import AddMeshcatTriad\nfrom manipulation.scenarios import AddMultibodyTriad\nfrom pydrake.all import (ConstantVectorSource, DiagramBuilder,\n                         FindResourceOrThrow, MeshcatVisualizer,\n                         MeshcatVisualizerParams, MultibodyPlant, Parser,\n                         PiecewisePolynomial, PiecewiseQuaternionSlerp,\n                         RigidTransform, RollPitchYaw, RotationMatrix,\n                         Simulator, Solve, StartMeshcat, TrajectorySource)\nfrom pydrake.examples.manipulation_station import ManipulationStation\nfrom pydrake.multibody import inverse_kinematics\nfrom pydrake.trajectories import PiecewisePolynomial\nfrom pydrake.trajectories import PiecewisePolynomial\n\n# Create a Drake temporary directory to store files.\n# Note: this tutorial will create two temporary files (cylinder.sdf and\n# table_top.sdf) under `/tmp/robotlocomotion_drake_xxxxxx` directory.\ntemp_dir = temp_directory()\n\n# Start the visualizer. The cell will output an HTTP link after the execution.\n# Click the link and a MeshCat tab should appear in your browser.\nmeshcat = StartMeshcat()\n\n# Press the 'Stop JointSliders' button in MeshCat to continue.\niiwa0 = FindResourceOrThrow(\n    \"drake/manipulation/models/\"\n    \"iiwa_description/iiwa7/iiwa7_with_box_collision.sdf\")\n# model_inspector(iiwa7_model_file)\n\n### PROJECT SDF FILES ###\n\n#Project XML file under Models Folder  \nproject_xml_file = os.path.join(\"/work/Models\", \"project.xml\")\nproject_xml = \"\"\"<?xml version=\"1.0\"?>\n<package>\n  <name>project</name>\n</package>\n\"\"\"\n\nwith open(project_xml_file, \"w\") as f:\n    f.write(project_xml)\n\n\n### GOALIE END-EFFECTOR\ngoalie_end_sdf_file = os.path.join(\"/work/Models\", \"goalie_end.sdf\")\ngoalie_end_sdf = \"\"\"<?xml version=\"1.0\"?>\n<package>\n  <name>project</name>\n</package>\n<sdf version=\"1.7\">\n  <model name=\"goalie_end\">\n    <link name=\"goalie_end_link\">\n    \n      <visual name=\"visual\">\n        <pose>0 0 0.15 0 0 0</pose>\n        <geometry>\n          <box>\n            <size>.30 .06 0.30</size>\n          </box>\n        </geometry>\n       \n      </visual>\n      \n      <collision name=\"collision\">\n        <pose>0 0 .15 0 0 0</pose>\n        <geometry>\n          <box>\n            <size>.30 .06 0.30</size>\n          </box>\n        </geometry>\n      </collision>\n    </link>\n    <frame name=\"goalie_end_center\">\n      <pose relative_to=\"goalie_end_link\">0 0 0.15 0 0 0</pose>\n    </frame>\n  </model>\n</sdf>\n\n\"\"\"\n\nwith open(goalie_end_sdf_file, \"w\") as f:\n    f.write(goalie_end_sdf)\n\n### GOAL POST:\ngoalpost_sdf_file = os.path.join(\"/work/Models\", \"goalpost.sdf\")\ngoalpost_sdf = \"\"\"\n<?xml version=\"1.0\"?>\n<package>\n  <name>project</name>\n</package>\n<sdf version=\"1.7\">\n  <model name=\"goalpost\">\n\n    <link name=\"goalpost_link\">\n\n      <visual name=\"visual\">\n        <pose>0 0 0 0 0 3.1415693</pose>\n        <geometry>\n            <mesh>\n                <uri>/work/soccerpostfixed.obj</uri>\n                <scale> 0.02 0.02 0.02 </scale>\n            </mesh>\n        </geometry>\n      </visual>\n\n      <collision name=\"collision\">\n         <pose>0.05  -0.4 0.6 0 0 0</pose>\n        <geometry>\n            <box>\n            <size>2 0.1 1.2</size>\n          </box>\n        </geometry>\n      </collision>\n\n    </link>\n\n    <frame name=\"goalpost_center\">\n      <pose relative_to =\"goalpost_link\">0 0 0.50 0 0 0</pose>\n    </frame>\n  </model>\n</sdf>\n\n\"\"\"\n\nwith open(goalpost_sdf_file, \"w\") as f:\n    f.write(goalpost_sdf)\n\n\n\n### Floor:\nfloor_sdf_file = os.path.join(\"/work/Models\", \"floor.sdf\")\nfloor_sdf = \"\"\"\n<?xml version=\"1.0\"?>\n<package>\n  <name>project</name>\n</package>\n<sdf version=\"1.7\">\n  <model name=\"floor\">\n\n    <link name=\"floor_link\">\n\n      <visual name=\"visual\">\n        <pose>0 0 0 0 0 0</pose>\n        <geometry>\n            <box>\n                <size>10 20 0.1</size>\n            </box>\n        </geometry>\n      </visual>\n\n      <collision name=\"collision\">\n         <pose>0 0 0 0 0 0</pose>\n        <geometry>\n            <box>\n            <size>10 20 0.1</size>\n          </box>\n        </geometry>\n      </collision>\n\n    </link>\n\n    <frame name=\"floor_center\">\n      <pose relative_to =\"floor_link\">0 0 .05 0 0 0</pose>\n    </frame>\n  </model>\n</sdf>\n\n\"\"\"\n\nwith open(floor_sdf_file, \"w\") as f:\n    f.write(floor_sdf)\n\n\n### SOCCER BALL\nSoccer_Ball_sdf_file = os.path.join(\"/work/Models\", \"Ball.sdf\")\nSoccer_Ball_sdf = \"\"\"<?xml version=\"1.0\"?>\n<package>\n  <name>project</name>\n</package>\n<sdf xmlns:xacro=\"http://www.ros.org/wiki/xacro\" version=\"1.7\">\n  <model name=\"Soccer Ball\">\n    <link name=\"Soccer_Ball_link\">\n\n      <inertial>\n        <pose>0 0 0.15 0 0 0</pose>\n        <mass>0.5</mass>\n        <inertia>\n          <ixx>0.008</ixx> \n          <iyy>0.008</iyy>\n          <izz>0.008</izz>\n          <ixy>0</ixy>\n          <ixz>0</ixz>\n          <iyz>0</iyz>\n        </inertia>\n      </inertial>\n\n\n      <visual name=\"visual\">\n        <pose>0 0 0.15 0 0 0</pose>\n        <geometry>\n          <mesh>\n            <uri>/work/Ball.obj</uri>\n            <scale> .1 .1 .1 </scale>\n          </mesh>\n        </geometry>\n\n        <material>\n         <diffuse>0.9 0.8 0.7 1.0</diffuse>\n        </material>\n      </visual>\n\n\n      <collision name=\"collision\">\n        <pose>0 0 .15 0 0 0</pose>\n        <geometry>\n          <sphere>\n            <radius>.1</radius>\n          </sphere>\n        </geometry>\n\n\n        <drake:proximity_properties>\n          <drake:point_contact_stiffness>\n            10000\n          </drake:point_contact_stiffness>\n          <drake:hunt_crossley_dissipation>\n            0.5\n          </drake:hunt_crossley_dissipation>\n        </drake:proximity_properties>\n\n\n      </collision>\n    </link>\n    <frame name=\"Soccer_ball_center\">\n      <pose relative_to=\"Soccer_Ball_link\">0 0 0 0 0 0</pose>\n    </frame>\n  </model>\n</sdf>\n\n\"\"\"\n\nwith open(Soccer_Ball_sdf_file, \"w\") as f:\n    f.write(Soccer_Ball_sdf)\n    \n\n# MODEL DIRECTIVES\nmodel_directives = \"\"\"\n    directives:\n    \n    \n\n    - add_model:\n        name: iiwa\n        file: package://drake/manipulation/models/iiwa_description/iiwa7/iiwa7_no_collision.sdf\n        default_joint_positions:\n            iiwa_joint_1: [0]\n            iiwa_joint_2: [0]\n            iiwa_joint_3: [1.5]\n            iiwa_joint_4: [1.5]\n            iiwa_joint_5: [0]\n            iiwa_joint_6: [1.57]\n            iiwa_joint_7: [0]\n         \n    - add_weld:\n        parent: world\n        child: iiwa::iiwa_link_0\n        X_PC:\n            translation: [0, 0, 0]\n            rotation: !Rpy { deg: [0, 0, 0]}\n    - add_model:\n        name: floor\n        file: package://project/floor.sdf\n    - add_weld:\n        parent: world\n        child: floor_center\n        X_PC:\n            translation: [0, 0, 0]\n            rotation: !Rpy { deg: [0, 0, 0]}\n    \n\n\n    - add_model:\n        name: goalie_end\n        file: package://project/goalie_end.sdf\n    - add_weld:\n        parent: iiwa::iiwa_link_7\n        child: goalie_end::goalie_end_link\n        X_PC:\n            translation: [0, 0, .04]\n            rotation: !Rpy { deg: [0, 0, 90]}\n    - add_model:\n        name: goalpost\n        file: package://project/goalpost.sdf\n    - add_weld:\n        parent: floor_center\n        child: goalpost_center\n        X_PC:\n            translation: [0, -0.8, 0.5]\n            rotation: !Rpy { deg: [0, 0, 0]}\n    - add_model:\n        name: Soccer_Ball\n        file: package://project/Ball.sdf\n        default_free_body_pose:\n            Soccer_Ball_link:\n                translation: [0, 5, 0]\n\n\n    \"\"\"","metadata":{"tags":[],"cell_id":"50f142249cfe4aefaee8a047876e8fb6","source_hash":"a48ebd43","execution_start":1671229200203,"execution_millis":609,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"INFO:drake:Meshcat listening for connections at https://c79dd6be-c791-4b96-b0a1-e37f965290d0.deepnoteproject.com/7000/\nInstalling NginX server for MeshCat on Deepnote...\n","output_type":"stream"},{"data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Meshcat URL: <a href='https://c79dd6be-c791-4b96-b0a1-e37f965290d0.deepnoteproject.com/7000/' target='_blank'>https://c79dd6be-c791-4b96-b0a1-e37f965290d0.deepnoteproject.com/7000/</a>"},"metadata":{},"output_type":"display_data"}],"execution_count":1},{"cell_type":"markdown","source":"### Randomized Ball Trajectory Code","metadata":{"tags":[],"cell_id":"618f0b1acf0e42c89cae16458da06d1c","is_collapsed":false,"formattedRanges":[],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"initial_soccer_params = {\n    \"s_ball_goalpost\": 3,\n    \"desired_approach_speed\": np.random.uniform(7,12), \n    \"x_range\": 0.80,\n    \"z_range\": 0.90\n}\n\n#ALSO RETURNS TIME OF FLIGHT FOR PROJECTILE:\ndef get_desired_velocity(desired_pos, params = initial_soccer_params):\n    \"\"\"\n    Given final x and z position of the ball when it enters the goal post, \n    returns Velocity vector with which ball should be launched from the initial position \n    \"\"\"\n    s,vy_des  = params[\"s_ball_goalpost\"],params[\"desired_approach_speed\"]\n    x_des,_,z_des = desired_pos\n\n    tau = s/vy_des #Time for ball to reach the goal post \n    vx_des = x_des/tau #No external force in x-direction\n    vz_des = (z_des + 1/2*9.81*tau**2)/tau\n    return (vx_des, -vy_des, vz_des), tau # vy = -vy because of the way we are simulating the env.  \n    \n\ndef randomize_ball_trajectory_w_time(params = initial_soccer_params):\n    x_rand = random.uniform(-params[\"x_range\"], params[\"x_range\"])\n    z_rand = random.uniform(0, params[\"z_range\"])\n    desired_pos = (x_rand,0.0, z_rand)\n   \n    v, tau = get_desired_velocity(desired_pos)\n\n    return v, desired_pos,tau\n\nrandomize_ball_trajectory_w_time()","metadata":{"tags":[],"cell_id":"14b93639486e4d72a6e73cd9ce97019f","source_hash":"5e51787f","execution_start":1671229200854,"execution_millis":5,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"((2.6244299345015505, -11.74972963356471, 3.500903526986059),\n (0.6700826358602774, 0.0, 0.5741070700371125),\n 0.2553250239418352)"},"metadata":{}}],"execution_count":2},{"cell_type":"markdown","source":"### Initial Setup","metadata":{"tags":[],"cell_id":"22791ae27df94a53a2e4d62ce2b649b9","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":13,"fromCodePoint":0}],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"import gym\nimport numpy as np\nimport math\nimport torch\nfrom pydrake.all import StartMeshcat\nfrom gym import spaces\nfrom collections import deque\n\nfrom stable_baselines3.common.env_checker import check_env\n\nfrom manipulation.utils import LoadDataResource, running_as_notebook\nfrom manipulation.envs.box_flipup import BoxFlipUpEnv\n\nfrom psutil import cpu_count\nnum_cpu = int(cpu_count() / 2) if running_as_notebook else 2\n\n# Optional imports (these are heavy dependencies for just this one notebook)\nsb3_available = False\ntry:\n    from stable_baselines3 import SAC\n    from stable_baselines3.common.vec_env import SubprocVecEnv\n    from stable_baselines3.common.env_util import make_vec_env\n    sb3_available = True\nexcept ImportError:\n    print(\"stable_baselines3 not found\")\n    print(\"Consider 'pip3 install stable_baselines3'.\")\n","metadata":{"tags":[],"cell_id":"1827cb3ab2814f06919a7b16e0b3f2f5","source_hash":"2a3418df","execution_start":1671229200855,"execution_millis":589,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"### GYM ENVIRONMENT:","metadata":{"tags":[],"cell_id":"9c0810619397435eb6223b0c5e14f378","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":16,"fromCodePoint":0}],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"class SoccerEnv(gym.Env):\n    \"\"\"Custom Environment that follows gym interface\"\"\"\n\n    def __init__(self):\n        super(SoccerEnv, self).__init__()\n\n        #Action space is delta of Joint Position: 7 DOF \n        self.action_space = spaces.Box(\n            low= -math.pi/90, \n            high= math.pi/90,\n            shape=(7,), \n            dtype=np.float32\n            )\n\n        \n        #Soccer X,Y,Z\n        #End-effector X,Z \n        #Last Joint Pose \n\n        self.observation_space = spaces.Box(\n                        low= np.append(np.array([-20, -20, -1.0,-0.3]),  np.full(7, -math.pi)), \n                        high=  np.append(np.array([20,20, 1.0,1.0]), np.full(7, math.pi)), shape=(11,), dtype=np.float32\n                        )\n\n\n        \n        self.params = initial_soccer_params\n\n        self.sim_time_step = 0.01\n\n        self.builder, self.station, self.plant, self.diagram, self.simulator, self.context, self.plant_context,self.q0, self.station_context= self.helper_initialize_soccer_env()\n        self.total_ep_reward = 0\n         \n\n    def step(self, action):\n        '''\n        Agent takes action -> New Observation and reward \n        '''\n        # print(\"delPosition: \",action)\n        self.JP += action\n\n        #Call helper function to actually step through drake simulation:\n        end_effector_XZ, ball_XZ, self.intercepted, rpy = self.helper_step_DrakeSimulation(JointPosition = self.JP)\n        \n        \n\n\n        #Observation:\n        ob = np.append(ball_XZ,end_effector_XZ)\n        observation = np.append(ob, self.JP) \n     \n\n        #Reward:\n        x_e,y_e = end_effector_XZ\n        x_b, y_b = ball_XZ   \n        r_0, y_0 = self.default_rpy[0], self.default_rpy[2]\n        r_cur, y_cur = rpy[0],rpy[2]\n        reward_orientation = -np.sqrt((r_0 - r_cur)**2 + (y_0 - y_cur)**2) \n\n\n        self.reward =  - np.sqrt((x_e - x_b)**2 + (y_e - y_b)**2)*10 + int(self.intercepted)*1000 + reward_orientation #Reward for smaller Distance \n        self.total_ep_reward += self.reward\n        # print(\"Orientation:\", reward_orientation/ self.reward)\n        #Info:\n        info = {}\n\n\n        #Done:\n        self.current_time += self.sim_time_step\n        self.done = self.current_time > self.terminal_time + 0.2\n\n        if self.intercepted:\n            print(\"Intercepted?\", self.intercepted )\n        # print(self.current_time)\n        # print(\"Ball: \", ball_XZ)\n        # print(\"End-effector:\", end_effector_XZ)\n        \n        # print(\"\\n\")\n        return observation, self.reward, self.done, info\n\n\n    def reset(self):\n        '''\n        Reset method\n        '''\n        #Initialize parameters and pose:\n\n        print(\"Total Ep. Reward: \", self.total_ep_reward)\n        self.done = False\n        self.total_ep_reward = 0 \n\n        self.JP = self.q0.copy() \n\n        end_effector_XZ, ball_XZ,tau = self.helper_reset_episode()\n        self.terminal_time = tau\n        self.current_time = 0\n\n        #Base Observation:\n        base_observation =   np.append(np.append(ball_XZ,end_effector_XZ), self.q0.copy()) \n        # print(tau)\n        return base_observation  # reward, done, info can't be \n\n    def render(self, mode = \"human\"):\n        self.visualizer.StartRecording(False)\n        # self.simulator.AdvanceTo(self.simulator.get_context().get_time()+self.sim_time_step)\n        self.visualizer.PublishRecording()\n\n    def close (self):\n        pass\n\n\n\n\n    def helper_initialize_soccer_env(self, params = initial_soccer_params):\n        \"\"\"\n        Helper function that initializes Soccerbot Environment withh class instance is created \n        \n        \"\"\"\n        meshcat.Delete()\n        meshcat.DeleteAddedControls()\n\n        builder = DiagramBuilder()\n        station = builder.AddSystem(\n            MakeManipulationStation(\n                model_directives, package_xmls=[\"/work/Models/project.xml\"], time_step =self.sim_time_step\n                )\n            )\n\n        plant = station.GetSubsystemByName(\"plant\")\n        controller_plant = station.GetSubsystemByName(\n            \"iiwa_controller\").get_multibody_plant_for_control()\n        scene_graph = station.GetSubsystemByName('scene_graph')\n        #station.SetupManipulationClassStation()\n\n        # Add a meshcat visualizer.\n        visualizer = MeshcatVisualizer.AddToBuilder(\n           builder, station.GetOutputPort(\"query_object\"), meshcat)\n        self.visualizer = visualizer\n        AddMultibodyTriad(\n            plant.GetFrameByName(\"goalie_end_link\"), scene_graph)\n        #station.Finalize()\n\n\n        diagram = builder.Build()\n        simulator = Simulator(diagram)\n        context = simulator.get_mutable_context()\n        station_context = station.GetMyMutableContextFromRoot(context)\n        plant_context = plant.GetMyMutableContextFromRoot(context)\n        q0 = np.array([0,0,1.57,1.57,0,1.57,0])\n\n\n        simulator.AdvanceTo(.001)\n\n        end_effector = plant.GetBodyByName(\"goalie_end_link\")\n        end_pose_RP = plant.EvalBodyPoseInWorld(plant_context, end_effector)\n        end_effector_pose = end_pose_RP.translation()\n        end_effector_rotation = end_pose_RP.rotation()\n        rpy = RollPitchYaw(end_effector_rotation).vector()\n\n        self.default_rpy = rpy\n        return builder, station, plant, diagram, simulator, context, plant_context,q0, station_context\n\n\n\n    def helper_reset_episode(self):\n        \"\"\"\n            - Set Ball and Manipulator to default position \n            - send ball at random trajectory Toward goal post \n\n            - Returns initial end-effector pose and ball pose \n        \"\"\"\n        v, desired_pos, tau = randomize_ball_trajectory_w_time()\n        vx, vy, vz = v\n        xf, yf, zf = desired_pos\n        soccer_ball_model = self.plant.GetModelInstanceByName('Soccer_Ball')\n        self.plant.SetPositions(self.plant_context,soccer_ball_model, np.array([1,0,0,0,0,self.params[\"s_ball_goalpost\"]+0.35, 0]))\n        self.plant.SetVelocities(self.plant_context,soccer_ball_model, np.array([0,0,0,vx,vy,vz]))\n\n        iiwa_model = self.plant.GetModelInstanceByName(\"iiwa\")\n        self.plant.SetPositions(self.plant_context, self.plant.GetModelInstanceByName('iiwa'), self.q0)\n    \n\n\n        end_effector = self.plant.GetBodyByName(\"goalie_end_link\")\n        \n        end_effector_pose = self.plant.EvalBodyPoseInWorld(self.plant_context, end_effector).translation()\n        # print(end_effector_pose)\n    \n\n        e_x, e_y, e_z = tuple(end_effector_pose)\n        end_effector_XZ  = np.array([end_effector_pose[0], end_effector_pose[2]])\n        \n        ball_XZ = np.zeros(2)\n        \n        return end_effector_XZ, ball_XZ, tau\n\n\n\n\n    def helper_step_DrakeSimulation(self,JointPosition):\n        '''\n        Helper function for step method:\n            - Given joint angles, steps single step in simulation\n            - Return current end-effector pose and ball pose \n        '''\n        JointLim = [2.97,1.2, 2.97, 1.85, 2.75, 2.05, 3.09]\n\n        for i in range(7):\n            if JointPosition[i] < -JointLim[i]: JointPosition[i] = -JointLim[i]\n            if JointPosition[i] >  JointLim[i]: JointPosition[i] = JointLim[i]\n    \n        iiwa_model = self.plant.GetModelInstanceByName(\"iiwa\")\n        self.station.GetInputPort('iiwa_position').FixValue(self.station_context, JointPosition)\n\n\n        ########\n\n        end_effector = self.plant.GetBodyByName(\"goalie_end_link\")\n        end_effector_pose = self.plant.EvalBodyPoseInWorld(self.plant_context, end_effector).translation()\n        end_effector_rotation = self.plant.EvalBodyPoseInWorld(self.plant_context, end_effector).rotation()\n        rpy = RollPitchYaw(end_effector_rotation).vector()\n\n\n        e_x, e_y, e_z = tuple(end_effector_pose)\n        end_effector_XZ  = np.array([end_effector_pose[0], end_effector_pose[2]])\n\n\n        soccer_ball_model = self.plant.GetModelInstanceByName('Soccer_Ball')\n        soccer_current_pose = self.plant.GetPositions(self.plant_context, soccer_ball_model) # 7 elements: 4 Quaternions, 3 positions\n        b_x, b_y, b_z = tuple(soccer_current_pose[4:])\n        ball_XZ  = np.array([soccer_current_pose[4], soccer_current_pose[6]])\n\n\n\n        intercepted = np.sqrt((e_x - b_x)**2 + (e_y - b_y)**2 + (e_z- 0.15 - b_z)**2)  < .30\n        solved = False\n\n\n        try: \n            self.simulator.AdvanceTo(self.sim_time_step + self.simulator.get_context().get_time())\n        except:\n            self.simulator.AdvanceTo(self.sim_time_step*2 + self.simulator.get_context().get_time())\n\n     \n        \n        return end_effector_XZ, ball_XZ, intercepted, rpy","metadata":{"tags":[],"cell_id":"5eb882cf4d9e4f95b2d87dc7392e13a5","source_hash":"82c1e6b3","execution_start":1671229201462,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"### Training,  Loading Model and Testing:","metadata":{"tags":[],"cell_id":"a44f0143d0e045dbb86a28d7c80ea210","is_collapsed":false,"formattedRanges":[{"type":"marks","marks":{"bold":true},"toCodePoint":37,"fromCodePoint":0}],"deepnote_cell_type":"text-cell-h3"}},{"cell_type":"code","source":"import gym\nimport numpy as np\n\nfrom stable_baselines3 import SAC\n\nenv = SoccerEnv()\n\nmodel = SAC(\"MlpPolicy\", env, verbose=1)\nmodel.learn(total_timesteps=500, log_interval=4)\nmodel.save(\"SAC_Soc\")\n\ndel model # remove to demonstrate saving and loading\n\nmodel = SAC.load(\"SAC_Soc\")\n\nobs = env.reset()\nfor i in range(1000):\n    action, _states = model.predict(obs, deterministic=True)\n    obs, reward, done, info = env.step(action)\n    \n    if done:\n        env.render()\n        obs = env.reset()","metadata":{"tags":[],"cell_id":"4ad41e68ec1f4323ba598cf911c1ce01","source_hash":"b9d30210","execution_start":1671229201467,"execution_millis":11156,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.8/dist-packages/gym/logger.py:34: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n  warnings.warn(colorize(\"%s: %s\" % (\"WARN\", msg % args), \"yellow\"))\nUsing cpu device\nWrapping the env with a `Monitor` wrapper\nWrapping the env in a DummyVecEnv.\nTotal Ep. Reward:  0\nTotal Ep. Reward:  -500.71255757915856\nTotal Ep. Reward:  -310.1558736630501\nTotal Ep. Reward:  -566.0136865131228\nTotal Ep. Reward:  -536.4092458139659\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 46       |\n|    ep_rew_mean     | -478     |\n| time/              |          |\n|    episodes        | 4        |\n|    fps             | 102      |\n|    time_elapsed    | 1        |\n|    total_timesteps | 184      |\n| train/             |          |\n|    actor_loss      | 2.29     |\n|    critic_loss     | 8.19     |\n|    ent_coef        | 0.976    |\n|    ent_coef_loss   | -0.289   |\n|    learning_rate   | 0.0003   |\n|    n_updates       | 83       |\n---------------------------------\nTotal Ep. Reward:  -566.8211577871895\nTotal Ep. Reward:  -337.6180227327961\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nTotal Ep. Reward:  4715.103705135563\nTotal Ep. Reward:  -571.0128835653089\n---------------------------------\n| rollout/           |          |\n|    ep_len_mean     | 46       |\n|    ep_rew_mean     | 166      |\n| time/              |          |\n|    episodes        | 8        |\n|    fps             | 61       |\n|    time_elapsed    | 5        |\n|    total_timesteps | 368      |\n| train/             |          |\n|    actor_loss      | -0.695   |\n|    critic_loss     | 44.9     |\n|    ent_coef        | 0.924    |\n|    ent_coef_loss   | -0.832   |\n|    learning_rate   | 0.0003   |\n|    n_updates       | 267      |\n---------------------------------\nTotal Ep. Reward:  -495.22322262757075\nTotal Ep. Reward:  -516.688221812703\nTotal Ep. Reward:  -418.9488854922533\nTotal Ep. Reward:  -616.5012136924702\nIntercepted? True\nIntercepted? True\nIntercepted? True\nTotal Ep. Reward:  2591.947286564009\nIntercepted? True\nIntercepted? True\nTotal Ep. Reward:  1617.6316833477406\nTotal Ep. Reward:  -470.6198075689197\nTotal Ep. Reward:  -557.9106673610711\nTotal Ep. Reward:  -533.3014861783232\nTotal Ep. Reward:  -524.2463979463536\nTotal Ep. Reward:  -384.29825115726806\nTotal Ep. Reward:  -415.6415960760419\nTotal Ep. Reward:  -601.8917404805222\nTotal Ep. Reward:  -474.69292381021523\nTotal Ep. Reward:  -398.134101142109\nTotal Ep. Reward:  -572.3918581171588\nTotal Ep. Reward:  -465.5414304215183\nTotal Ep. Reward:  -407.0479998288804\nIntercepted? True\nIntercepted? True\nIntercepted? True\nTotal Ep. Reward:  2605.529530086693\nTotal Ep. Reward:  -472.7061861696285\nIntercepted? True\nIntercepted? True\nIntercepted? True\nTotal Ep. Reward:  2612.9628482136163\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nIntercepted? True\nTotal Ep. Reward:  12601.816304027261\nIntercepted? True\nIntercepted? True\nTotal Ep. Reward:  1646.730811330873\nTotal Ep. Reward:  -429.80854900597444\n","output_type":"stream"}],"execution_count":5},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=c79dd6be-c791-4b96-b0a1-e37f965290d0' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"9ab5811a1cf24ffdb99f6cc2ed4303a5","deepnote_execution_queue":[]}}